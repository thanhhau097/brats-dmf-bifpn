{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: dockerfile=Dockerfile\n",
      "env: account=533155507761\n",
      "env: region=us-west-2\n",
      "env: repo_name=ocr\n",
      "env: image_tag=prj_scsk\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import os \n",
    "import sagemaker\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# Define instance configurations \n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "repo_name = 'sagemaker-test'  # ECR repository\n",
    "image_tag = 'sagemaker-test'  # ECR image tag\n",
    "base_job_name = 'sagemaker-test'  # SageMaker training prefix\n",
    "# dockerfile = os.path.abspath('./new_dockerfile')\n",
    "\n",
    "%env dockerfile Dockerfile\n",
    "%env account {account}\n",
    "%env region {region}\n",
    "%env repo_name {repo_name}\n",
    "%env image_tag {image_tag}\n",
    "\n",
    "# print(\"Account: {0}\".format(account))\n",
    "# print(\"Region: {0}\".format(region))\n",
    "# print(\"Repo name: {0}\".format(repo_name))\n",
    "# print(\"Image tag: {0}\".format(image_tag))\n",
    "# print(\"Base job name: {0}\".format(base_job_name))\n",
    "# print(\"Docker file: {0}\".format(dockerfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "aws ecr describe-repositories --repository-names $repo_name > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "   aws ecr create-repository --repository-name $repo_name > /dev/null\n",
    "fi\n",
    "$(aws ecr get-login --region $region --no-include-email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon    962kB\n",
      "Step 1/19 : FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
      " ---> a686b859d874\n",
      "Step 2/19 : ARG py_version=3\n",
      " ---> Using cache\n",
      " ---> d4b7cb27814a\n",
      "Step 3/19 : RUN test $py_version || exit 1\n",
      " ---> Using cache\n",
      " ---> 80d8d4794836\n",
      "Step 4/19 : RUN apt-get update && apt-get install -y --no-install-recommends software-properties-common &&     add-apt-repository ppa:deadsnakes/ppa -y &&     apt-get update && apt-get install -y --no-install-recommends         build-essential         cmake         curl         jq         libsm6         libxext6         libxrender-dev         nginx &&     if [ $py_version -eq 3 ];        then apt-get install -y --no-install-recommends python3.6-dev            && ln -s -f /usr/bin/python3.6 /usr/bin/python;        else apt-get install -y --no-install-recommends python-dev; fi &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 0ac0df63eae8\n",
      "Step 5/19 : RUN cd /tmp &&     curl -O https://bootstrap.pypa.io/get-pip.py &&     python get-pip.py && rm get-pip.py\n",
      " ---> Using cache\n",
      " ---> 9320a1942783\n",
      "Step 6/19 : RUN pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 718c073cdd43\n",
      "Step 7/19 : ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1 PYTHONIOENCODING=UTF-8 LANG=C.UTF-8 LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 4d53ef798418\n",
      "Step 8/19 : RUN apt-get update     && apt-get install -y git\n",
      " ---> Using cache\n",
      " ---> e6c08b32f67f\n",
      "Step 9/19 : RUN rm -rf /opt/ml/code/\n",
      " ---> Using cache\n",
      " ---> d1107ce80713\n",
      "Step 10/19 : COPY . /opt/ml/code/\n",
      " ---> ffa7d1db218f\n",
      "Step 11/19 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Running in 542e19a6b23a\n",
      "Removing intermediate container 542e19a6b23a\n",
      " ---> 32904e68ca9d\n",
      "Step 12/19 : RUN rm -rf /root/.cache\n",
      " ---> Running in 4df6ac526afe\n",
      "Removing intermediate container 4df6ac526afe\n",
      " ---> 044250a88f85\n",
      "Step 13/19 : RUN rm -rf /var/lib/apt/lists/* ~/.cache/pip\n",
      " ---> Running in 70d931bd5040\n",
      "Removing intermediate container 70d931bd5040\n",
      " ---> 67b2a666a2c7\n",
      "Step 14/19 : RUN apt-get autoremove && apt-get clean\n",
      " ---> Running in 5bd798602105\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n",
      "Removing intermediate container 5bd798602105\n",
      " ---> 6a5b45d9143d\n",
      "Step 15/19 : RUN unlink /etc/localtime\n",
      " ---> Running in b6566ed636d6\n",
      "Removing intermediate container b6566ed636d6\n",
      " ---> d2b72b1148ca\n",
      "Step 16/19 : RUN ln -s /usr/share/zoneinfo/Asia/Ho_Chi_Minh /etc/localtime\n",
      " ---> Running in 63308dbcc731\n",
      "Removing intermediate container 63308dbcc731\n",
      " ---> d70b7518bb7f\n",
      "Step 17/19 : WORKDIR /opt/ml/code/\n",
      " ---> Running in de253c92cb9e\n",
      "Removing intermediate container de253c92cb9e\n",
      " ---> a53753d12574\n",
      "Step 18/19 : ENV export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-9.0/lib64\n",
      " ---> Running in 10e5c6c0fee2\n",
      "Removing intermediate container 10e5c6c0fee2\n",
      " ---> 5bf2f5058d79\n",
      "Step 19/19 : ENTRYPOINT [\"python\", \"main.py\", \"--config\", \"configs/sagemaker_config.json\"]\n",
      " ---> Running in 295be4b6031c\n",
      "Removing intermediate container 295be4b6031c\n",
      " ---> d066dad1b42f\n",
      "Successfully built d066dad1b42f\n",
      "Successfully tagged prj_scsk:latest\n",
      "REPOSITORY                                               TAG                             IMAGE ID            CREATED                  SIZE\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         latest                          d066dad1b42f        Less than a second ago   2.97GB\n",
      "prj_scsk                                                 latest                          d066dad1b42f        Less than a second ago   2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         <none>                          5cecb7bbf973        9 minutes ago            2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         <none>                          c3025f0cbeae        39 minutes ago           2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/anson-ocr   latest                          4ce048fec0f4        About an hour ago        4.05GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         <none>                          2224f0379086        2 hours ago              2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         <none>                          d01147b46b80        2 hours ago              2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/anson-ocr   <none>                          9fd4052a7cda        2 hours ago              4.05GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr         <none>                          c2589f6765a4        3 hours ago              2.97GB\n",
      "533155507761.dkr.ecr.us-west-2.amazonaws.com/anson-ocr   <none>                          6bc7fb550ac7        3 hours ago              4.05GB\n",
      "nvidia/cuda                                              10.0-cudnn7-devel-ubuntu16.04   edbd625b9042        6 days ago               3.11GB\n",
      "nvidia/cuda                                              9.0-cudnn7-devel-ubuntu16.04    a686b859d874        6 days ago               2.72GB\n",
      "The push refers to repository [533155507761.dkr.ecr.us-west-2.amazonaws.com/ocr]\n",
      "\n",
      "\u001b[1Bf39e99fb: Preparing \n",
      "\u001b[1B7cf9ba34: Preparing \n",
      "\u001b[1B48307637: Preparing \n",
      "\u001b[1B71916fcb: Preparing \n",
      "\u001b[1Bf073cf39: Preparing \n",
      "\u001b[1B16f6d11c: Preparing \n",
      "\u001b[1B60e8e792: Preparing \n",
      "\u001b[1Baba96a42: Preparing \n",
      "\u001b[1B3f6baa5f: Preparing \n",
      "\u001b[1B9ad8f46c: Preparing \n",
      "\u001b[1B3d00e3e2: Preparing \n",
      "\u001b[1Bcef4ab1b: Preparing \n",
      "\u001b[1B3277e2ee: Preparing \n",
      "\u001b[1B62c32538: Preparing \n",
      "\u001b[1Baf8eabd8: Preparing \n",
      "\u001b[1B0239569d: Preparing \n",
      "\u001b[1B42719515: Preparing \n",
      "\u001b[1B103e78c9: Preparing \n",
      "\u001b[1Be637fbff: Preparing \n",
      "\u001b[15B6f6d11c: Pushed lready exists 1kBshing     512B\u001b[17A\u001b[1K\u001b[K\u001b[20A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[K\u001b[12A\u001b[1K\u001b[K\u001b[8A\u001b[1K\u001b[K\u001b[3A\u001b[1K\u001b[K\u001b[15A\u001b[1K\u001b[Klatest: digest: sha256:04554c6443a3c789de593e6f0f001ef8aad378c8a0a6d77a077873e901d27084 size: 4507\n"
     ]
    }
   ],
   "source": [
    "# # Build docker and push to ionstance\n",
    "# subprocess.run(\"docker build -t {0} -f {1} . \".format(image_tag, dockerfile), shell=True)\n",
    "# subprocess.run(\"docker tag {0} {1}.dkr.ecr.{2}.amazonaws.com/{3}:latest\".format(image_tag, account, region, repo_name), shell=True)\n",
    "# subprocess.run(\"docker push {0}.dkr.ecr.{1}.amazonaws.com/{2}:latest\".format(account, region, repo_name), shell=True)\n",
    "\n",
    "!docker build -t $image_tag -f $dockerfile .\n",
    "!docker tag $image_tag $account.dkr.ecr.$region.amazonaws.com/$repo_name:latest\n",
    "!docker images\n",
    "!docker push $account.dkr.ecr.$region.amazonaws.com/$repo_name:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define data path in S3 \n",
    "s3_directory = 's3://scsk-data/lionel/brats'\n",
    "train_input_channel = sagemaker.session.s3_input(s3_directory, distribution='FullyReplicated',  s3_data_type='S3Prefix')\n",
    "\n",
    "# checkpoint uri for spot training\n",
    "checkpoint_s3_uri = 's3://scsk-data/lionel/checkpoints/' + repo_name\n",
    "\n",
    "# Define image name, output path to save model \n",
    "output_path = 's3://scsk-data/ocr_data/output/lionel'\n",
    "image_name  = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, repo_name)\n",
    "\n",
    "## Define instance to train \n",
    "train_instance_type = 'ml.p3.2xlarge'\n",
    "# train_instance_type = 'ml.p3.8xlarge'\n",
    "\n",
    "# Define space of disk to storage input data\n",
    "storage_space = 200 # Gb\n",
    "\n",
    "# Maximum seconds for this training job’s life (days * hours * seconds)\n",
    "train_max_run = 1 * 24 * 3600\n",
    "train_max_wait = 3 * 24  * 3600 + 12 * 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-05 08:01:55 Starting - Starting the training job...\n",
      "2019-08-05 08:01:57 Starting - Launching requested ML instances......\n",
      "2019-08-05 08:03:08 Starting - Preparing the instances for training......\n",
      "2019-08-05 08:03:57 Downloading - Downloading input data...\n",
      "2019-08-05 08:04:38 Training - Downloading the training image......\n",
      "2019-08-05 08:05:45 Training - Training image download completed. Training in progress.\n",
      "\u001b[31mInstalling requirements...\u001b[0m\n",
      "\u001b[31mCollecting tensorflow-gpu==1.12.0 (from -r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/55/7e/bec4d62e9dc95e828922c6cec38acd9461af8abe749f7c9def25ec4b2fdb/tensorflow_gpu-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (281.7MB)\u001b[0m\n",
      "\u001b[31mCollecting keras==2.2.4 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\u001b[0m\n",
      "\u001b[31mCollecting numpy (from -r requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/19/b9/bda9781f0a74b90ebd2e046fde1196182900bd4a8e1ea503d3ffebc50e7c/numpy-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (20.4MB)\u001b[0m\n",
      "\u001b[31mCollecting tqdm (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/9f/3d/7a6b68b631d2ab54975f3a4863f3c4e9b26445353264ef01f465dc9b0208/tqdm-4.32.2-py2.py3-none-any.whl (50kB)\u001b[0m\n",
      "\u001b[31mCollecting opencv-python (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/d2/a2dbf83d4553ca6b3701d91d75e42fe50aea97acdc00652dca515749fb5d/opencv_python-4.1.0.25-cp36-cp36m-manylinux1_x86_64.whl (26.6MB)\u001b[0m\n",
      "\u001b[31mCollecting comet_ml (from -r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/52/11f789dbf6e757a9831ad54c0850d2a0c2822866e65e899a94bba8e824b2/comet_ml-2.0.5-py3-none-any.whl (111kB)\u001b[0m\n",
      "\u001b[31mCollecting scikit-learn (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[31m  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\u001b[0m\n",
      "\u001b[31mCollecting pillow (from -r requirements.txt (line 8))\n",
      "  Downloading https://files.pythonhosted.org/packages/14/41/db6dec65ddbc176a59b89485e8cc136a433ed9c6397b6bfe2cd38412051e/Pillow-6.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\u001b[0m\n",
      "\u001b[31mCollecting editdistance (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[31m  Downloading https://files.pythonhosted.org/packages/77/67/2b1fe72bdd13ee9ec32b97959d7dfbfcd7c0548081d69aaf8493c1e695f9/editdistance-0.5.3-cp36-cp36m-manylinux1_x86_64.whl (178kB)\u001b[0m\n",
      "\u001b[31mCollecting dotmap (from -r requirements.txt (line 10))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/a6/0f88e89673285daf190891985ad8b57d1d70ec4ccaf2d53b692e25f52ad4/dotmap-1.3.8-py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting gast>=0.2.0 (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting six>=1.10.0 (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting tensorboard<1.13.0,>=1.12.0 (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\u001b[0m\n",
      "\u001b[31mCollecting astor>=0.6.0 (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting keras-applications>=1.0.6 (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\u001b[0m\n",
      "\u001b[31mCollecting termcolor>=1.1.0 (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1)) (0.33.4)\u001b[0m\n",
      "\u001b[31mCollecting protobuf>=3.6.1 (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[31m  Downloading https://files.pythonhosted.org/packages/dc/0e/e7cdff89745986c984ba58e6ff6541bc5c388dd9ab9d7d312b3b1532584a/protobuf-3.9.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\u001b[0m\n",
      "\u001b[31mCollecting keras-preprocessing>=1.0.5 (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\u001b[0m\n",
      "\u001b[31mCollecting grpcio>=1.8.6 (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/5d/b434403adb2db8853a97828d3d19f2032e79d630e0d11a8e95d243103a11/grpcio-1.22.0-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\u001b[0m\n",
      "\u001b[31mCollecting absl-py>=0.1.6 (from tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\u001b[0m\n",
      "\u001b[31mCollecting h5py (from keras==2.2.4->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\u001b[0m\n",
      "\u001b[31mCollecting pyyaml (from keras==2.2.4->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/e8/b3212641ee2718d556df0f23f78de8303f068fe29cdaa7a91018849582fe/PyYAML-5.1.2.tar.gz (265kB)\u001b[0m\n",
      "\u001b[31mCollecting scipy>=0.14 (from keras==2.2.4->-r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/72/4c/5f81e7264b0a7a8bd570810f48cd346ba36faedbd2ba255c873ad556de76/scipy-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (25.2MB)\u001b[0m\n",
      "\u001b[31mCollecting everett[ini]>=1.0.1; python_version >= \"3.0\" (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/34/de70a3d913411e40ce84966f085b5da0c6df741e28c86721114dd290aaa0/everett-1.0.2-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting jsonschema>=2.6.0 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/54/48/f5f11003ceddcd4ad292d4d9b5677588e9169eef41f88e38b2888e7ec6c4/jsonschema-3.0.2-py2.py3-none-any.whl (54kB)\u001b[0m\n",
      "\u001b[31mCollecting wurlitzer>=1.0.2 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/09/56/201c4d13c37b6fb0cb5dbf1d026a2fec14fd151fd4f3f1dc1144d6273fd3/wurlitzer-1.0.3-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting comet-git-pure>=0.19.11 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/48/ae/a3d9b28e1d909bddbdba8ef7c331542614f3bf9fbba31bd4380c3294c569/comet_git_pure-0.19.11-py3-none-any.whl (383kB)\u001b[0m\n",
      "\u001b[31mCollecting netifaces>=0.10.7 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/9b/c4c7eb09189548d45939a3d3a6b3d53979c67d124459b27a094c365c347f/netifaces-0.10.9-cp36-cp36m-manylinux1_x86_64.whl\u001b[0m\n",
      "\u001b[31mCollecting requests>=2.18.4 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\u001b[0m\n",
      "\u001b[31mCollecting websocket-client>=0.55.0 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\u001b[0m\n",
      "\u001b[31mCollecting nvidia-ml-py3>=7.352.0 (from comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/64/cce82bddb80c0b0f5c703bbdafa94bfb69a1c5ad7a79cff00b482468f0d3/nvidia-ml-py3-7.352.0.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting joblib>=0.11 (from scikit-learn->-r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\u001b[0m\n",
      "\u001b[31mCollecting markdown>=2.6.8 (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\u001b[0m\n",
      "\u001b[31mCollecting werkzeug>=0.11.10 (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu==1.12.0->-r requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/ab/d3bed6b92042622d24decc7aadc8877badf18aeca1571045840ad4956d3f/Werkzeug-0.15.5-py2.py3-none-any.whl (328kB)\u001b[0m\n",
      "\u001b[31mRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.12.0->-r requirements.txt (line 1)) (41.0.1)\u001b[0m\n",
      "\u001b[31mCollecting configobj; extra == \"ini\" (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/64/61/079eb60459c44929e684fa7d9e2fdca403f67d64dd9dbac27296be2e0fab/configobj-5.0.6.tar.gz\u001b[0m\n",
      "\u001b[31mCollecting attrs>=17.4.0 (from jsonschema>=2.6.0->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/23/96/d828354fa2dbdf216eaa7b7de0db692f12c234f7ef888cc14980ef40d1d2/attrs-19.1.0-py2.py3-none-any.whl\u001b[0m\n",
      "\u001b[31mCollecting pyrsistent>=0.14.0 (from jsonschema>=2.6.0->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/66/b2638d96a2d128b168d0dba60fdc77b7800a9b4a5340cefcc5fc4eae6295/pyrsistent-0.15.4.tar.gz (107kB)\u001b[0m\n",
      "\u001b[31mCollecting urllib3>=1.23 (from comet-git-pure>=0.19.11->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/60/247f23a7121ae632d62811ba7f273d0e58972d75e58a94d329d51550a47d/urllib3-1.25.3-py2.py3-none-any.whl (150kB)\u001b[0m\n",
      "\u001b[31mCollecting certifi (from comet-git-pure>=0.19.11->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/69/1b/b853c7a9d4f6a6d00749e94eb6f3a041e342a885b87340b79c1ef73e3a78/certifi-2019.6.16-py2.py3-none-any.whl (157kB)\u001b[0m\n",
      "\u001b[31mCollecting chardet<3.1.0,>=3.0.2 (from requests>=2.18.4->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\u001b[0m\n",
      "\u001b[31mCollecting idna<2.9,>=2.5 (from requests>=2.18.4->comet_ml->-r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: gast, termcolor, absl-py, pyyaml, nvidia-ml-py3, configobj, pyrsistent\n",
      "  Building wheel for gast (setup.py): started\u001b[0m\n",
      "\u001b[31m  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7541 sha256=d22b9813bb369fd2875393996dd82dfa4e58a28d7a94d81738a6f5cd74bc8c6b\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-cp36-none-any.whl size=4833 sha256=79556f462e0971b8dd884f418a603194cef031a1e887dcb74a777b93b72a5fc4\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.7.1-cp36-none-any.whl size=117848 sha256=45456296089bcfdbb001db40e3c38bc3a43e7da945f5c93bec274cf727d48267\n",
      "  Stored in directory: /root/.cache/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Building wheel for pyyaml (setup.py): started\u001b[0m\n",
      "\u001b[31m  Building wheel for pyyaml (setup.py): finished with status 'done'\n",
      "  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp36-cp36m-linux_x86_64.whl size=44105 sha256=912c731f585be76ff614e32e36adfdcc1adb04b570d20c034592ef965a4c2f41\n",
      "  Stored in directory: /root/.cache/pip/wheels/d9/45/dd/65f0b38450c47cf7e5312883deb97d065e030c5cca0a365030\n",
      "  Building wheel for nvidia-ml-py3 (setup.py): started\n",
      "  Building wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\n",
      "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-cp36-none-any.whl size=19193 sha256=0caff95763c5a5f9283725e6247c6de1313fd4cde1c9e9414198e44b2a2b27d5\n",
      "  Stored in directory: /root/.cache/pip/wheels/e4/1d/06/640c93f5270d67d0247f30be91f232700d19023f9e66d735c7\n",
      "  Building wheel for configobj (setup.py): started\n",
      "  Building wheel for configobj (setup.py): finished with status 'done'\n",
      "  Created wheel for configobj: filename=configobj-5.0.6-cp36-none-any.whl size=34547 sha256=05e83d3a2076e571b1145f107ce8dda9264bbcbf440fb6bbd3601f535a8edce5\n",
      "  Stored in directory: /root/.cache/pip/wheels/f1/e4/16/4981ca97c2d65106b49861e0b35e2660695be7219a2d351ee0\n",
      "  Building wheel for pyrsistent (setup.py): started\u001b[0m\n",
      "\u001b[31m  Building wheel for pyrsistent (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrsistent: filename=pyrsistent-0.15.4-cp36-cp36m-linux_x86_64.whl size=94338 sha256=b5494701c67156879a1ea513388e616d78883e4202cdf0b98fb6ee054a728f32\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/46/00/6d471ef0b813e3621f0abe6cb723c20d529d39a061de3f7c51\u001b[0m\n",
      "\u001b[31mSuccessfully built gast termcolor absl-py pyyaml nvidia-ml-py3 configobj pyrsistent\u001b[0m\n",
      "\u001b[31mInstalling collected packages: gast, six, protobuf, numpy, markdown, werkzeug, grpcio, tensorboard, astor, h5py, keras-applications, termcolor, keras-preprocessing, absl-py, tensorflow-gpu, pyyaml, scipy, keras, tqdm, opencv-python, configobj, everett, attrs, pyrsistent, jsonschema, wurlitzer, urllib3, certifi, comet-git-pure, netifaces, chardet, idna, requests, websocket-client, nvidia-ml-py3, comet-ml, joblib, scikit-learn, pillow, editdistance, dotmap\u001b[0m\n",
      "\u001b[31mSuccessfully installed absl-py-0.7.1 astor-0.8.0 attrs-19.1.0 certifi-2019.6.16 chardet-3.0.4 comet-git-pure-0.19.11 comet-ml-2.0.5 configobj-5.0.6 dotmap-1.3.8 editdistance-0.5.3 everett-1.0.2 gast-0.2.2 grpcio-1.22.0 h5py-2.9.0 idna-2.8 joblib-0.13.2 jsonschema-3.0.2 keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 netifaces-0.10.9 numpy-1.17.0 nvidia-ml-py3-7.352.0 opencv-python-4.1.0.25 pillow-6.1.0 protobuf-3.9.0 pyrsistent-0.15.4 pyyaml-5.1.2 requests-2.22.0 scikit-learn-0.21.3 scipy-1.3.0 six-1.12.0 tensorboard-1.12.2 tensorflow-gpu-1.12.0 termcolor-1.1.0 tqdm-4.32.2 urllib3-1.25.3 websocket-client-0.56.0 werkzeug-0.15.5 wurlitzer-1.0.3\u001b[0m\n",
      "\u001b[31mDoing unzip file /opt/ml/input/data/train/data.zip:\u001b[0m\n",
      "\u001b[31mMon Aug  5 08:07:01 2019       \u001b[0m\n",
      "\u001b[31m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[31m| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\u001b[0m\n",
      "\u001b[31m|-------------------------------+----------------------+----------------------+\u001b[0m\n",
      "\u001b[31m| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\u001b[0m\n",
      "\u001b[31m| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\u001b[0m\n",
      "\u001b[31m|===============================+======================+======================|\u001b[0m\n",
      "\u001b[31m|   0  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\u001b[0m\n",
      "\u001b[31m| N/A   35C    P0    24W / 300W |      0MiB / 16130MiB |      0%      Default |\u001b[0m\n",
      "\u001b[31m+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \u001b[0m\n",
      "\u001b[31m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[31m| Processes:                                                       GPU Memory |\u001b[0m\n",
      "\u001b[31m|  GPU       PID   Type   Process name                             Usage      |\u001b[0m\n",
      "\u001b[31m|=============================================================================|\u001b[0m\n",
      "\u001b[31m|  No running processes found                                                 |\u001b[0m\n",
      "\u001b[31m+-----------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[31mRUN TRAIN.PY FILE\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\u001b[0m\n",
      "\u001b[31mBuilding vocabulary\u001b[0m\n",
      "\u001b[31mNumber of characters: 3800\u001b[0m\n",
      "\u001b[31mCreate the model.\u001b[0m\n",
      "\u001b[31m2019-08-05 08:07:03.272341: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\u001b[0m\n",
      "\u001b[31m2019-08-05 08:07:03.479372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\u001b[0m\n",
      "\u001b[31m2019-08-05 08:07:03.480331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \u001b[0m\n",
      "\u001b[31mname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\u001b[0m\n",
      "\u001b[31mpciBusID: 0000:00:1e.0\u001b[0m\n",
      "\u001b[31mtotalMemory: 15.75GiB freeMemory: 15.44GiB\u001b[0m\n",
      "\u001b[31m2019-08-05 08:07:03.480364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\u001b[0m\n",
      "\u001b[31m2019-08-05 08:07:03.925859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\u001b[0m\n",
      "\u001b[31m2019-08-05 08:07:03.925902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \u001b[0m\n",
      "\u001b[31m2019-08-05 08:07:03.925912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \u001b[0m\n",
      "\u001b[31m2019-08-05 08:07:03.926016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14944 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:1e.0, compute capability: 7.0)\u001b[0m\n",
      "\u001b[31mDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf.h5\u001b[0m\n",
      "\u001b[31m    8192/17225924 [..............................] - ETA: 0s\n",
      "   24576/17225924 [..............................] - ETA: 48s\n",
      "   57344/17225924 [..............................] - ETA: 41s\n",
      "  122880/17225924 [..............................] - ETA: 29s\n",
      "  262144/17225924 [..............................] - ETA: 18s\n",
      "  573440/17225924 [..............................] - ETA: 10s\n",
      " 1171456/17225924 [=>............................] - ETA: 5s \n",
      " 2359296/17225924 [===>..........................] - ETA: 3s\u001b[0m\n",
      "\u001b[31m 3948544/17225924 [=====>........................] - ETA: 1s\n",
      " 5521408/17225924 [========>.....................] - ETA: 1s\n",
      " 7110656/17225924 [===========>..................] - ETA: 0s\n",
      " 8699904/17225924 [==============>...............] - ETA: 0s\u001b[0m\n",
      "\u001b[31m10289152/17225924 [================>.............] - ETA: 0s\u001b[0m\n",
      "\u001b[31m11862016/17225924 [===================>..........] - ETA: 0s\u001b[0m\n",
      "\u001b[31m13451264/17225924 [======================>.......] - ETA: 0s\u001b[0m\n",
      "\u001b[31m15040512/17225924 [=========================>....] - ETA: 0s\u001b[0m\n",
      "\u001b[31m16629760/17225924 [===========================>..] - ETA: 0s\u001b[0m\n",
      "\u001b[31m17227776/17225924 [==============================] - 1s 0us/step\u001b[0m\n",
      "\u001b[31mAfter Encoder: Tensor(\"conv_pw_5_relu/Relu6:0\", shape=(?, ?, 8, 256), dtype=float32)\u001b[0m\n",
      "\u001b[31mAfter CNN to RNN: Tensor(\"dense1/Relu:0\", shape=(?, ?, 256), dtype=float32)\u001b[0m\n",
      "\u001b[31mAfter Decoder: Tensor(\"concatenate_1/concat:0\", shape=(?, ?, 512), dtype=float32)\u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                    Output Shape         Param #     Connected to                     \u001b[0m\n",
      "\u001b[31m==================================================================================================\u001b[0m\n",
      "\u001b[31mthe_input (InputLayer)          (None, None, 64, 3)  0                                            \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv1_pad (ZeroPadding2D)       (None, None, 65, 3)  0           the_input[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv1 (Conv2D)                  (None, None, 32, 32) 864         conv1_pad[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv1_bn (BatchNormalization)   (None, None, 32, 32) 128         conv1[0][0]                      \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv1_relu (ReLU)               (None, None, 32, 32) 0           conv1_bn[0][0]                   \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_1 (DepthwiseConv2D)     (None, None, 32, 32) 288         conv1_relu[0][0]                 \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_1_bn (BatchNormalizatio (None, None, 32, 32) 128         conv_dw_1[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_1_relu (ReLU)           (None, None, 32, 32) 0           conv_dw_1_bn[0][0]               \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_1 (Conv2D)              (None, None, 32, 64) 2048        conv_dw_1_relu[0][0]             \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_1_bn (BatchNormalizatio (None, None, 32, 64) 256         conv_pw_1[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_1_relu (ReLU)           (None, None, 32, 64) 0           conv_pw_1_bn[0][0]               \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pad_2 (ZeroPadding2D)      (None, None, 33, 64) 0           conv_pw_1_relu[0][0]             \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_2 (DepthwiseConv2D)     (None, None, 16, 64) 576         conv_pad_2[0][0]                 \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_2_bn (BatchNormalizatio (None, None, 16, 64) 256         conv_dw_2[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_2_relu (ReLU)           (None, None, 16, 64) 0           conv_dw_2_bn[0][0]               \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_2 (Conv2D)              (None, None, 16, 128 8192        conv_dw_2_relu[0][0]             \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_2_bn (BatchNormalizatio (None, None, 16, 128 512         conv_pw_2[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_2_relu (ReLU)           (None, None, 16, 128 0           conv_pw_2_bn[0][0]               \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_3 (DepthwiseConv2D)     (None, None, 16, 128 1152        conv_pw_2_relu[0][0]             \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_3_bn (BatchNormalizatio (None, None, 16, 128 512         conv_dw_3[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_3_relu (ReLU)           (None, None, 16, 128 0           conv_dw_3_bn[0][0]               \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_3 (Conv2D)              (None, None, 16, 128 16384       conv_dw_3_relu[0][0]             \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_3_bn (BatchNormalizatio (None, None, 16, 128 512         conv_pw_3[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_3_relu (ReLU)           (None, None, 16, 128 0           conv_pw_3_bn[0][0]               \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pad_4 (ZeroPadding2D)      (None, None, 17, 128 0           conv_pw_3_relu[0][0]             \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_4 (DepthwiseConv2D)     (None, None, 8, 128) 1152        conv_pad_4[0][0]                 \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_4_bn (BatchNormalizatio (None, None, 8, 128) 512         conv_dw_4[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_4_relu (ReLU)           (None, None, 8, 128) 0           conv_dw_4_bn[0][0]               \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_4 (Conv2D)              (None, None, 8, 256) 32768       conv_dw_4_relu[0][0]             \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_4_bn (BatchNormalizatio (None, None, 8, 256) 1024        conv_pw_4[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_4_relu (ReLU)           (None, None, 8, 256) 0           conv_pw_4_bn[0][0]               \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_5 (DepthwiseConv2D)     (None, None, 8, 256) 2304        conv_pw_4_relu[0][0]             \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_5_bn (BatchNormalizatio (None, None, 8, 256) 1024        conv_dw_5[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_dw_5_relu (ReLU)           (None, None, 8, 256) 0           conv_dw_5_bn[0][0]               \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_5 (Conv2D)              (None, None, 8, 256) 65536       conv_dw_5_relu[0][0]             \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_5_bn (BatchNormalizatio (None, None, 8, 256) 1024        conv_pw_5[0][0]                  \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconv_pw_5_relu (ReLU)           (None, None, 8, 256) 0           conv_pw_5_bn[0][0]               \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mreshape (Reshape)               (None, None, 2048)   0           conv_pw_5_relu[0][0]             \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdense1 (Dense)                  (None, None, 256)    524544      reshape[0][0]                    \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mgru1 (CuDNNGRU)                 (None, None, 256)    394752      dense1[0][0]                     \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mgru1_b (CuDNNGRU)               (None, None, 256)    394752      dense1[0][0]                     \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31madd_1 (Add)                     (None, None, 256)    0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mgru2 (CuDNNGRU)                 (None, None, 256)    394752      add_1[0][0]                      \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mgru2_b (CuDNNGRU)               (None, None, 256)    394752      add_1[0][0]                      \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mconcatenate_1 (Concatenate)     (None, None, 512)    0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mdense2 (Dense)                  (None, None, 3801)   1949913     concatenate_1[0][0]              \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31msoftmax (Activation)            (None, None, 3801)   0           dense2[0][0]                     \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mthe_labels (InputLayer)         (None, 64)           0                                            \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31minput_length (InputLayer)       (None, 1)            0                                            \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mlabel_length (InputLayer)       (None, 1)            0                                            \u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \u001b[0m\n",
      "\u001b[31m==================================================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 4,190,617\u001b[0m\n",
      "\u001b[31mTrainable params: 4,187,673\u001b[0m\n",
      "\u001b[31mNon-trainable params: 2,944\u001b[0m\n",
      "\u001b[31m__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[31mCreate the data generator.\u001b[0m\n",
      "\u001b[31mCreate the trainer\u001b[0m\n",
      "\u001b[31mStart training the model.\u001b[0m\n",
      "\u001b[31mEpoch 1/20\u001b[0m\n",
      "\u001b[31m   1/5000 [..............................] - ETA: 17:52:28 - loss: 1758.9072\u001b[0m\n",
      "\u001b[31m   2/5000 [..............................] - ETA: 9:26:53 - loss: 1353.8656 \u001b[0m\n",
      "\u001b[31m   3/5000 [..............................] - ETA: 6:50:43 - loss: 1331.7959\u001b[0m\n",
      "\u001b[31m   4/5000 [..............................] - ETA: 5:32:06 - loss: 1165.7842\u001b[0m\n",
      "\u001b[31m   5/5000 [..............................] - ETA: 4:43:54 - loss: 969.8688 \u001b[0m\n",
      "\u001b[31m   6/5000 [..............................] - ETA: 4:11:29 - loss: 820.7462\u001b[0m\n",
      "\u001b[31m   7/5000 [..............................] - ETA: 3:55:00 - loss: 721.2965\u001b[0m\n",
      "\u001b[31m   8/5000 [..............................] - ETA: 3:34:52 - loss: 645.9565\u001b[0m\n",
      "\u001b[31m   9/5000 [..............................] - ETA: 3:18:53 - loss: 588.2611\u001b[0m\n",
      "\u001b[31m  10/5000 [..............................] - ETA: 3:08:29 - loss: 544.3649\u001b[0m\n",
      "\u001b[31m  11/5000 [..............................] - ETA: 2:58:10 - loss: 502.2597\u001b[0m\n",
      "\u001b[31m  12/5000 [..............................] - ETA: 2:48:07 - loss: 466.1318\u001b[0m\n",
      "\u001b[31m  13/5000 [..............................] - ETA: 2:42:36 - loss: 436.7068\u001b[0m\n",
      "\u001b[31m  14/5000 [..............................] - ETA: 2:37:13 - loss: 412.6402\u001b[0m\n",
      "\u001b[31m  15/5000 [..............................] - ETA: 2:32:59 - loss: 391.5748\u001b[0m\n",
      "\u001b[31m  16/5000 [..............................] - ETA: 2:28:28 - loss: 372.5177\u001b[0m\n",
      "\u001b[31m  17/5000 [..............................] - ETA: 2:25:14 - loss: 356.4486\u001b[0m\n",
      "\u001b[31m  18/5000 [..............................] - ETA: 2:22:41 - loss: 341.3563\u001b[0m\n",
      "\u001b[31m  19/5000 [..............................] - ETA: 2:21:25 - loss: 327.9447\u001b[0m\n",
      "\u001b[31m  20/5000 [..............................] - ETA: 2:20:20 - loss: 316.1327\u001b[0m\n",
      "\u001b[31m  21/5000 [..............................] - ETA: 2:16:40 - loss: 305.3552\u001b[0m\n",
      "\u001b[31m  22/5000 [..............................] - ETA: 2:13:45 - loss: 294.0342\u001b[0m\n",
      "\u001b[31m  23/5000 [..............................] - ETA: 2:10:46 - loss: 284.8966\u001b[0m\n",
      "\u001b[31m  24/5000 [..............................] - ETA: 2:08:33 - loss: 277.0687\u001b[0m\n",
      "\u001b[31m  25/5000 [..............................] - ETA: 2:07:14 - loss: 269.0593\u001b[0m\n",
      "\u001b[31m  26/5000 [..............................] - ETA: 2:05:30 - loss: 261.3540\u001b[0m\n",
      "\u001b[31m  27/5000 [..............................] - ETA: 2:03:25 - loss: 253.7573\u001b[0m\n",
      "\u001b[31m  28/5000 [..............................] - ETA: 2:02:42 - loss: 247.4432\u001b[0m\n",
      "\u001b[31m  29/5000 [..............................] - ETA: 2:00:49 - loss: 241.5020\u001b[0m\n",
      "\u001b[31m  30/5000 [..............................] - ETA: 2:00:04 - loss: 235.9330\u001b[0m\n",
      "\u001b[31m  31/5000 [..............................] - ETA: 1:59:23 - loss: 230.7412\n",
      "  32/5000 [..............................] - ETA: 1:59:27 - loss: 226.5128\u001b[0m\n",
      "\u001b[31m  33/5000 [..............................] - ETA: 1:57:16 - loss: 221.4528\n",
      "  34/5000 [..............................] - ETA: 1:55:32 - loss: 217.0590\u001b[0m\n",
      "\u001b[31m  35/5000 [..............................] - ETA: 1:53:37 - loss: 212.8968\u001b[0m\n",
      "\u001b[31m  36/5000 [..............................] - ETA: 1:52:36 - loss: 209.0733\u001b[0m\n",
      "\u001b[31m  37/5000 [..............................] - ETA: 1:51:39 - loss: 205.4563\u001b[0m\n",
      "\u001b[31m  38/5000 [..............................] - ETA: 1:50:34 - loss: 202.0189\u001b[0m\n",
      "\u001b[31m  39/5000 [..............................] - ETA: 1:49:57 - loss: 199.0764\u001b[0m\n",
      "\u001b[31m  40/5000 [..............................] - ETA: 1:49:37 - loss: 195.6161\u001b[0m\n",
      "\u001b[31m  41/5000 [..............................] - ETA: 1:48:33 - loss: 192.2929\u001b[0m\n",
      "\u001b[31m  42/5000 [..............................] - ETA: 1:47:44 - loss: 189.4418\u001b[0m\n",
      "\u001b[31m  43/5000 [..............................] - ETA: 1:46:44 - loss: 186.4597\u001b[0m\n",
      "\u001b[31m  44/5000 [..............................] - ETA: 1:46:18 - loss: 183.9789\u001b[0m\n",
      "\u001b[31m  45/5000 [..............................] - ETA: 1:45:57 - loss: 181.4978\u001b[0m\n",
      "\u001b[31m  46/5000 [..............................] - ETA: 1:45:15 - loss: 178.9265\u001b[0m\n",
      "\u001b[31m  47/5000 [..............................] - ETA: 1:44:29 - loss: 176.4062\u001b[0m\n",
      "\u001b[31m  48/5000 [..............................] - ETA: 1:43:38 - loss: 174.0560\u001b[0m\n",
      "\u001b[31m  49/5000 [..............................] - ETA: 1:43:10 - loss: 171.7154\u001b[0m\n",
      "\u001b[31m  50/5000 [..............................] - ETA: 1:42:50 - loss: 169.7328\u001b[0m\n",
      "\u001b[31m  51/5000 [..............................] - ETA: 1:42:49 - loss: 167.4774\u001b[0m\n",
      "\u001b[31m  52/5000 [..............................] - ETA: 1:42:18 - loss: 165.6471\u001b[0m\n",
      "\u001b[31m  53/5000 [..............................] - ETA: 1:43:00 - loss: 163.6534\n",
      "  54/5000 [..............................] - ETA: 1:42:38 - loss: 161.9930\u001b[0m\n",
      "\u001b[31m  55/5000 [..............................] - ETA: 1:41:59 - loss: 160.2108\u001b[0m\n",
      "\u001b[31m  56/5000 [..............................] - ETA: 1:41:25 - loss: 158.6244\u001b[0m\n",
      "\u001b[31m  57/5000 [..............................] - ETA: 1:40:45 - loss: 156.7137\n",
      "  58/5000 [..............................] - ETA: 1:41:06 - loss: 155.5571\u001b[0m\n",
      "\u001b[31m  59/5000 [..............................] - ETA: 1:40:24 - loss: 154.1829\u001b[0m\n",
      "\u001b[31m  60/5000 [..............................] - ETA: 1:39:36 - loss: 152.8101\u001b[0m\n",
      "\u001b[31m  61/5000 [..............................] - ETA: 1:39:15 - loss: 151.7057\u001b[0m\n",
      "\u001b[31m  62/5000 [..............................] - ETA: 1:39:41 - loss: 150.9946\u001b[0m\n",
      "\u001b[31m  63/5000 [..............................] - ETA: 1:39:16 - loss: 149.4580\u001b[0m\n",
      "\u001b[31m  64/5000 [..............................] - ETA: 1:38:51 - loss: 148.5093\u001b[0m\n",
      "\u001b[31m  65/5000 [..............................] - ETA: 1:38:55 - loss: 147.2173\u001b[0m\n",
      "\u001b[31m  66/5000 [..............................] - ETA: 1:38:48 - loss: 146.3503\n",
      "  67/5000 [..............................] - ETA: 1:38:40 - loss: 145.0052\u001b[0m\n",
      "\u001b[31m  68/5000 [..............................] - ETA: 1:38:08 - loss: 143.9898\u001b[0m\n",
      "\u001b[31m  69/5000 [..............................] - ETA: 1:38:00 - loss: 142.8692\u001b[0m\n",
      "\u001b[31m  70/5000 [..............................] - ETA: 1:37:53 - loss: 141.7283\u001b[0m\n",
      "\u001b[31m  71/5000 [..............................] - ETA: 1:37:26 - loss: 140.6898\u001b[0m\n",
      "\u001b[31m  72/5000 [..............................] - ETA: 1:37:17 - loss: 139.6788\n",
      "  73/5000 [..............................] - ETA: 1:37:16 - loss: 138.7695\u001b[0m\n",
      "\u001b[31m  74/5000 [..............................] - ETA: 1:36:43 - loss: 137.6592\u001b[0m\n",
      "\u001b[31m  75/5000 [..............................] - ETA: 1:36:10 - loss: 136.5732\u001b[0m\n",
      "\u001b[31m  76/5000 [..............................] - ETA: 1:35:35 - loss: 135.5715\u001b[0m\n",
      "\u001b[31m  77/5000 [..............................] - ETA: 1:35:30 - loss: 134.9571\n",
      "  78/5000 [..............................] - ETA: 1:35:56 - loss: 134.2343\u001b[0m\n",
      "\u001b[31m  79/5000 [..............................] - ETA: 1:35:37 - loss: 133.4006\u001b[0m\n",
      "\u001b[31m  80/5000 [..............................] - ETA: 1:35:12 - loss: 132.6686\u001b[0m\n",
      "\u001b[31m  81/5000 [..............................] - ETA: 1:35:03 - loss: 131.9437\u001b[0m\n",
      "\u001b[31m  82/5000 [..............................] - ETA: 1:35:11 - loss: 131.1176\u001b[0m\n",
      "\u001b[31m  83/5000 [..............................] - ETA: 1:34:30 - loss: 130.0579\u001b[0m\n",
      "\u001b[31m  84/5000 [..............................] - ETA: 1:34:01 - loss: 129.3744\u001b[0m\n",
      "\u001b[31m  85/5000 [..............................] - ETA: 1:33:53 - loss: 128.8637\u001b[0m\n",
      "\u001b[31m  86/5000 [..............................] - ETA: 1:33:50 - loss: 128.4473\u001b[0m\n",
      "\u001b[31m  87/5000 [..............................] - ETA: 1:33:29 - loss: 127.8004\u001b[0m\n",
      "\u001b[31m  88/5000 [..............................] - ETA: 1:33:35 - loss: 127.1800\u001b[0m\n",
      "\u001b[31m  89/5000 [..............................] - ETA: 1:33:25 - loss: 126.6403\u001b[0m\n",
      "\u001b[31m  90/5000 [..............................] - ETA: 1:33:42 - loss: 126.2326\u001b[0m\n",
      "\u001b[31m  91/5000 [..............................] - ETA: 1:33:55 - loss: 125.4953\u001b[0m\n",
      "\u001b[31m  92/5000 [..............................] - ETA: 1:33:48 - loss: 124.9469\u001b[0m\n",
      "\u001b[31m  93/5000 [..............................] - ETA: 1:33:50 - loss: 124.5520\u001b[0m\n",
      "\u001b[31m  94/5000 [..............................] - ETA: 1:33:30 - loss: 123.9911\u001b[0m\n",
      "\u001b[31m  95/5000 [..............................] - ETA: 1:33:13 - loss: 123.3768\u001b[0m\n",
      "\u001b[31m  96/5000 [..............................] - ETA: 1:33:14 - loss: 122.8853\u001b[0m\n",
      "\u001b[31m  97/5000 [..............................] - ETA: 1:33:21 - loss: 122.4327\u001b[0m\n",
      "\u001b[31m  98/5000 [..............................] - ETA: 1:33:05 - loss: 121.8425\u001b[0m\n",
      "\u001b[31m  99/5000 [..............................] - ETA: 1:32:58 - loss: 121.2697\u001b[0m\n",
      "\u001b[31m 100/5000 [..............................] - ETA: 1:32:56 - loss: 120.7692\u001b[0m\n",
      "\u001b[31m 101/5000 [..............................] - ETA: 1:32:49 - loss: 120.1270\u001b[0m\n",
      "\u001b[31m 102/5000 [..............................] - ETA: 1:32:41 - loss: 119.7700\u001b[0m\n",
      "\u001b[31m 103/5000 [..............................] - ETA: 1:32:30 - loss: 119.1367\u001b[0m\n",
      "\u001b[31m 104/5000 [..............................] - ETA: 1:32:38 - loss: 118.6512\u001b[0m\n",
      "\u001b[31m 105/5000 [..............................] - ETA: 1:33:01 - loss: 118.1568\u001b[0m\n",
      "\u001b[31m 106/5000 [..............................] - ETA: 1:33:02 - loss: 118.0675\u001b[0m\n",
      "\u001b[31m 107/5000 [..............................] - ETA: 1:32:56 - loss: 117.5599\n",
      " 108/5000 [..............................] - ETA: 1:32:31 - loss: 116.9736\u001b[0m\n",
      "\u001b[31m 109/5000 [..............................] - ETA: 1:32:13 - loss: 116.3986\u001b[0m\n",
      "\u001b[31m 110/5000 [..............................] - ETA: 1:32:14 - loss: 115.8851\n",
      " 111/5000 [..............................] - ETA: 1:32:00 - loss: 115.3347\u001b[0m\n",
      "\u001b[31m 112/5000 [..............................] - ETA: 1:31:48 - loss: 115.0172\u001b[0m\n",
      "\u001b[31m 113/5000 [..............................] - ETA: 1:32:03 - loss: 114.6660\u001b[0m\n",
      "\u001b[31m 114/5000 [..............................] - ETA: 1:31:46 - loss: 114.2477\u001b[0m\n",
      "\u001b[31m 115/5000 [..............................] - ETA: 1:31:46 - loss: 113.9600\u001b[0m\n",
      "\u001b[31m 116/5000 [..............................] - ETA: 1:31:35 - loss: 113.6410\u001b[0m\n",
      "\u001b[31m 117/5000 [..............................] - ETA: 1:31:43 - loss: 113.5015\u001b[0m\n",
      "\u001b[31m 118/5000 [..............................] - ETA: 1:31:23 - loss: 113.0496\u001b[0m\n",
      "\u001b[31m 119/5000 [..............................] - ETA: 1:31:20 - loss: 112.7248\n",
      " 120/5000 [..............................] - ETA: 1:31:05 - loss: 112.1596\u001b[0m\n",
      "\u001b[31m 121/5000 [..............................] - ETA: 1:30:54 - loss: 111.8191\n",
      " 122/5000 [..............................] - ETA: 1:30:52 - loss: 111.4801\u001b[0m\n",
      "\u001b[31m 123/5000 [..............................] - ETA: 1:30:44 - loss: 111.2418\u001b[0m\n",
      "\u001b[31m 124/5000 [..............................] - ETA: 1:30:40 - loss: 110.8805\u001b[0m\n",
      "\u001b[31m 125/5000 [..............................] - ETA: 1:30:22 - loss: 110.4468\u001b[0m\n",
      "\u001b[31m 126/5000 [..............................] - ETA: 1:30:16 - loss: 110.1998\u001b[0m\n",
      "\u001b[31m 127/5000 [..............................] - ETA: 1:29:55 - loss: 109.7475\u001b[0m\n",
      "\u001b[31m 128/5000 [..............................] - ETA: 1:29:54 - loss: 109.3828\u001b[0m\n",
      "\u001b[31m 129/5000 [..............................] - ETA: 1:29:45 - loss: 109.1114\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set sagemaker estimator and process to train\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "                       image_name=image_name,\n",
    "                       base_job_name=base_job_name,\n",
    "                       role=role,\n",
    "                       input_mode='File',\n",
    "                       train_instance_count=1,\n",
    "                       train_use_spot_instances=True, \n",
    "                       train_max_wait=train_max_wait,\n",
    "                       train_volume_size=storage_space,\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       output_path=output_path,\n",
    "                       train_max_run=train_max_run,\n",
    "                       sagemaker_session=sess,\n",
    "                       checkpoint_s3_uri=checkpoint_s3_uri)\n",
    "\n",
    "estimator.fit({'train': train_input_channel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}